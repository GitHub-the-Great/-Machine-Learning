{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a8c54b-3928-4b51-abc8-58ba549d5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/jupyter-lcstw596113/.local/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "=== NEU-DET Object Detection with Improved YOLO ===\n",
      "\n",
      "1. Converting dataset to YOLO format...\n",
      "Converting dataset: 979 train, 173 val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train set: 100%|██████████| 979/979 [00:01<00:00, 574.19it/s]\n",
      "Converting val set: 100%|██████████| 173/173 [00:00<00:00, 601.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset created successfully!\n",
      "\n",
      "2. Initializing YOLO trainer...\n",
      "\n",
      "3. Starting training...\n",
      "Model loaded and ready for training\n",
      "Starting training with improved YOLO model...\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./yolo_dataset/dataset.yaml, degrees=15.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=neudet_improved, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/neudet_improved, save_frames=False, save_json=True, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3779170  ultralytics.nn.modules.head.Detect           [6, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,859,794 parameters, 25,859,778 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 80.4±15.3 MB/s, size: 19.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/labels/train... 1363 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1363/1363 [00:00<00:00, 2820.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/images/train/crazing_cd8qlpy8vdtf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/images/train/inclusion_3pohbuffg14b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/images/train/patches_3ac4zfsisba7.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 40.1±13.9 MB/s, size: 10.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/labels/val... 399 images, 0 backgrounds, 0 corrupt: 100%|██████████| 399/399 [00:00<00:00, 2232.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/images/val/inclusion_3pohbuffg14b.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/jp/LCS/Machine Learning/Final Project/yolo_dataset/labels/val.cache\n",
      "Plotting labels to runs/detect/neudet_improved/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/neudet_improved\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/150      6.35G      1.893      2.682      2.115          8        640: 100%|██████████| 86/86 [00:19<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.751      0.239      0.315      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/150      7.56G       1.77       2.32      2.048         20        640: 100%|██████████| 86/86 [00:20<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.401       0.23      0.192     0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/150      7.56G      1.782      2.273      2.057         18        640: 100%|██████████| 86/86 [00:10<00:00,  8.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.312      0.387      0.137     0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/150      7.57G      1.734      2.207      2.018         16        640: 100%|██████████| 86/86 [00:09<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.307      0.396      0.226     0.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/150      7.57G      1.738      2.174      1.991         11        640: 100%|██████████| 86/86 [00:09<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.488      0.322      0.326       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/150      7.57G      1.661      2.055      1.952         19        640: 100%|██████████| 86/86 [00:10<00:00,  8.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.499      0.253       0.23      0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/150      7.57G      1.667      2.053      1.957         17        640: 100%|██████████| 86/86 [00:09<00:00,  8.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.551      0.399       0.37      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/150      7.57G      1.662      2.036      1.955         10        640: 100%|██████████| 86/86 [00:09<00:00,  8.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.663      0.429      0.501      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/150      7.57G      1.637      1.978      1.907         19        640: 100%|██████████| 86/86 [00:10<00:00,  8.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.57      0.489      0.467       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/150      7.57G      1.625      1.989      1.921         17        640: 100%|██████████| 86/86 [00:09<00:00,  8.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.727       0.41      0.451      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/150      7.57G      1.583      1.901      1.873         17        640: 100%|██████████| 86/86 [00:09<00:00,  8.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.717      0.505      0.582      0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/150      7.57G      1.581      1.932      1.868         11        640: 100%|██████████| 86/86 [00:09<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.444      0.535      0.517       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/150      7.57G      1.546      1.825      1.838         16        640: 100%|██████████| 86/86 [00:09<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.427      0.494      0.447      0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/150      7.57G      1.595      1.894       1.88          9        640: 100%|██████████| 86/86 [00:09<00:00,  8.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:02<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.511      0.622      0.566      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/150      7.57G      1.558      1.844       1.85         14        640: 100%|██████████| 86/86 [00:10<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.498      0.599      0.578       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/150      7.57G      1.554      1.822      1.847         19        640: 100%|██████████| 86/86 [00:23<00:00,  3.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:09<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.466      0.544      0.526      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/150      7.57G      1.549      1.839       1.83         10        640: 100%|██████████| 86/86 [00:23<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.662      0.534      0.579      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/150      7.57G      1.538      1.814      1.836         10        640: 100%|██████████| 86/86 [00:23<00:00,  3.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:09<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.65        0.5      0.563      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/150      7.57G      1.514      1.764      1.812         24        640: 100%|██████████| 86/86 [00:24<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.79      0.441      0.597      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/150      7.64G      1.535      1.786      1.839         19        640: 100%|██████████| 86/86 [00:31<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:16<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.675      0.595      0.622      0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/150      7.64G      1.509      1.768       1.82         16        640: 100%|██████████| 86/86 [00:40<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:16<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.578      0.647      0.639      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/150      7.64G      1.547      1.809      1.839         16        640: 100%|██████████| 86/86 [00:36<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.573      0.642      0.642      0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/150      7.64G      1.508       1.78      1.808         20        640: 100%|██████████| 86/86 [00:17<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.617      0.657      0.676      0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/150      7.64G       1.51      1.754      1.809         12        640: 100%|██████████| 86/86 [00:21<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.619      0.647      0.671      0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/150      7.64G      1.524      1.747      1.824         20        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.601      0.648      0.688      0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/150      7.64G      1.508      1.701      1.807         10        640: 100%|██████████| 86/86 [00:17<00:00,  4.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.575      0.636      0.644       0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/150      7.64G      1.491      1.717      1.795         12        640: 100%|██████████| 86/86 [00:17<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.607      0.646      0.645      0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/150      7.64G      1.491      1.726      1.805         15        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.564      0.694      0.677      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/150      7.64G      1.492      1.707      1.781         20        640: 100%|██████████| 86/86 [00:21<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.509      0.613       0.61      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/150      7.64G      1.477      1.666      1.785         16        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.65      0.586      0.648      0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/150      7.64G      1.456      1.652      1.772         29        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.599      0.657      0.659      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/150      7.64G       1.47      1.663      1.763         17        640: 100%|██████████| 86/86 [00:20<00:00,  4.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.634      0.652      0.644      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/150      7.64G      1.467      1.648      1.774          9        640: 100%|██████████| 86/86 [00:20<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.677      0.642      0.711      0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/150      7.64G       1.45      1.642      1.755          9        640: 100%|██████████| 86/86 [00:17<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.649      0.653      0.674      0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/150      7.64G      1.455      1.618      1.779         16        640: 100%|██████████| 86/86 [00:17<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.605      0.637      0.644      0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/150      7.64G      1.459      1.671      1.783         12        640: 100%|██████████| 86/86 [00:19<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:08<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.554      0.702       0.69       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/150      7.64G       1.41      1.571      1.726          9        640: 100%|██████████| 86/86 [00:21<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.638      0.683      0.707      0.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/150      7.64G      1.453      1.597      1.749         28        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.635      0.689      0.704      0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/150      7.64G      1.433       1.62      1.739         13        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.661       0.67       0.71      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/150      7.64G      1.438      1.614      1.749         30        640: 100%|██████████| 86/86 [00:19<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.783      0.594      0.701      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/150      7.64G      1.416      1.579      1.739          7        640: 100%|██████████| 86/86 [00:20<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.658      0.718      0.734      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/150      7.64G      1.424      1.591      1.743         16        640: 100%|██████████| 86/86 [00:18<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.708       0.69      0.764      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/150      7.64G      1.416      1.541      1.726         18        640: 100%|██████████| 86/86 [00:17<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.726      0.641       0.69       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/150      7.64G      1.432      1.578      1.739         12        640: 100%|██████████| 86/86 [00:20<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.803      0.644      0.734      0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/150      7.64G      1.421      1.575      1.741         21        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.618      0.723      0.708       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/150      7.64G      1.418      1.575      1.754         13        640: 100%|██████████| 86/86 [00:18<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.616      0.676      0.717      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/150      7.64G      1.405      1.516      1.722         12        640: 100%|██████████| 86/86 [00:17<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.638      0.689      0.729      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/150      7.64G      1.404      1.558       1.74         22        640: 100%|██████████| 86/86 [00:20<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.524      0.544      0.561      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/150      7.64G      1.416      1.546      1.743         15        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.709       0.66      0.743      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/150      7.64G      1.394       1.52      1.715         17        640: 100%|██████████| 86/86 [00:18<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.658      0.712       0.74      0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/150      7.64G      1.413      1.528      1.727         22        640: 100%|██████████| 86/86 [00:18<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.692      0.649      0.697       0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/150      7.64G      1.406      1.524      1.727         12        640: 100%|██████████| 86/86 [00:25<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:13<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.608      0.719      0.693       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/150      7.64G      1.403      1.542       1.72         18        640: 100%|██████████| 86/86 [00:27<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.77       0.66      0.767      0.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/150      7.64G        1.4      1.515      1.734         17        640: 100%|██████████| 86/86 [00:26<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:11<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.705      0.628        0.7       0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/150      7.64G      1.407      1.504      1.713         20        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.643      0.663      0.732      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/150      7.64G      1.414      1.538      1.719          9        640: 100%|██████████| 86/86 [00:18<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.748      0.704      0.776      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/150      7.64G      1.377      1.479        1.7         22        640: 100%|██████████| 86/86 [00:21<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.64       0.72      0.728      0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/150      7.64G      1.394      1.462      1.695         13        640: 100%|██████████| 86/86 [00:20<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.729      0.699      0.784       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/150      7.64G      1.406      1.512      1.722         17        640: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.69      0.735      0.782      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/150      7.64G      1.391      1.519      1.706         16        640: 100%|██████████| 86/86 [00:18<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.731      0.695      0.761      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/150      7.64G      1.404      1.456      1.702         23        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.741      0.722       0.77      0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/150      7.64G      1.351      1.448      1.676         10        640: 100%|██████████| 86/86 [00:20<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.752      0.708      0.784      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/150      7.64G      1.364      1.473      1.697         23        640: 100%|██████████| 86/86 [00:17<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857        0.7      0.767        0.8      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/150      7.65G      1.338      1.433      1.674         14        640: 100%|██████████| 86/86 [00:16<00:00,  5.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.731      0.688      0.744      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/150      7.65G       1.35      1.427      1.674         16        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.695      0.741       0.79      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/150       7.7G      1.345      1.447      1.669         11        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.692       0.73      0.779      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/150       7.7G      1.362      1.438      1.691         17        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.753      0.724      0.779      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/150       7.7G      1.358      1.446      1.689         22        640: 100%|██████████| 86/86 [00:17<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.751       0.73      0.791      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/150       7.7G      1.368      1.434      1.693         22        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.726      0.782      0.818      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/150       7.7G      1.346      1.399      1.667         17        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.754       0.76      0.804       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/150       7.7G      1.345       1.42      1.678         27        640: 100%|██████████| 86/86 [00:17<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.704      0.732      0.781      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/150       7.7G      1.355      1.432      1.681         14        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.708       0.72      0.779      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/150       7.7G      1.347      1.424      1.662         19        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.829      0.734      0.819      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/150       7.7G      1.361      1.405       1.68         18        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.763      0.732      0.803      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/150       7.7G      1.365      1.412      1.681         14        640: 100%|██████████| 86/86 [00:17<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.764      0.752      0.824      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/150       7.7G      1.317      1.355      1.644         12        640: 100%|██████████| 86/86 [00:17<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.764      0.682      0.788      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/150       7.7G      1.326      1.362      1.657          8        640: 100%|██████████| 86/86 [00:20<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.781      0.718      0.815      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/150       7.7G      1.347      1.401      1.693         15        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.78       0.76      0.819      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/150       7.7G      1.334      1.396      1.665         17        640: 100%|██████████| 86/86 [00:18<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.687       0.73      0.769      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/150       7.7G      1.348      1.432      1.683         14        640: 100%|██████████| 86/86 [00:17<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.735      0.762      0.822      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/150       7.7G      1.319      1.383      1.646         14        640: 100%|██████████| 86/86 [00:19<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.769      0.781      0.841      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/150       7.7G        1.3       1.34      1.635         15        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.758      0.796      0.843      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/150       7.7G      1.325      1.365       1.66         11        640: 100%|██████████| 86/86 [00:18<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.758      0.756      0.829      0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/150       7.7G      1.313      1.355      1.643         14        640: 100%|██████████| 86/86 [00:17<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.779       0.77      0.844      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/150       7.7G      1.309      1.321      1.629         22        640: 100%|██████████| 86/86 [00:19<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.723      0.759      0.813      0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/150       7.7G      1.325      1.365       1.66         14        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.786      0.782       0.83      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/150       7.7G      1.307      1.335      1.643         15        640: 100%|██████████| 86/86 [00:19<00:00,  4.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.79      0.761      0.839      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/150       7.7G      1.314      1.342      1.643          9        640: 100%|██████████| 86/86 [00:17<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.819       0.76      0.855      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/150       7.7G      1.295      1.326      1.635          9        640: 100%|██████████| 86/86 [00:18<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.74      0.754      0.812      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/150       7.7G       1.29       1.31      1.619         17        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.831      0.754      0.845      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/150       7.7G      1.305      1.335      1.646         21        640: 100%|██████████| 86/86 [00:19<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.791      0.779      0.853      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/150       7.7G      1.287      1.329      1.638         15        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.717      0.814      0.847      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/150       7.7G      1.311      1.337      1.645         23        640: 100%|██████████| 86/86 [00:18<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.831      0.761       0.86      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/150       7.7G       1.28      1.291      1.623         26        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.764      0.818      0.853      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/150       7.7G      1.309      1.304      1.643         15        640: 100%|██████████| 86/86 [00:20<00:00,  4.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.747       0.83      0.862      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/150       7.7G      1.267      1.275      1.617         13        640: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.808      0.783      0.851      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/150       7.7G      1.298        1.3      1.624         12        640: 100%|██████████| 86/86 [00:17<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.77      0.823      0.862      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/150       7.7G      1.282      1.263      1.615         24        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.861      0.763      0.869      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/150       7.7G      1.283      1.277      1.619         13        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.784      0.779      0.839      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/150       7.7G      1.289      1.285      1.618         17        640: 100%|██████████| 86/86 [00:17<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.864      0.788      0.878      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    101/150       7.7G      1.249      1.266      1.597         11        640: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.805      0.796      0.871      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    102/150       7.7G      1.281      1.269      1.608         16        640: 100%|██████████| 86/86 [00:21<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.833      0.802      0.886      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    103/150       7.7G      1.251      1.251      1.588         13        640: 100%|██████████| 86/86 [00:21<00:00,  4.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.836      0.761       0.87       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    104/150       7.7G      1.266      1.253        1.6          7        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.834      0.793      0.871      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/150       7.7G       1.25      1.233      1.594         11        640: 100%|██████████| 86/86 [00:17<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.811      0.843      0.883      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    106/150       7.7G      1.258      1.225      1.595         12        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.81      0.807      0.875      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    107/150       7.7G      1.265      1.242        1.6         13        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.797      0.784      0.877      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    108/150       7.7G      1.256       1.23      1.594         27        640: 100%|██████████| 86/86 [00:17<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.78      0.797      0.876      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    109/150       7.7G       1.23      1.205      1.578         22        640: 100%|██████████| 86/86 [00:17<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.839       0.81      0.884      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    110/150       7.7G      1.247      1.217      1.599         17        640: 100%|██████████| 86/86 [00:20<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.832      0.786      0.875      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    111/150       7.7G      1.251      1.207      1.601         22        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.81      0.824      0.888      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    112/150       7.7G      1.245      1.233      1.596         22        640: 100%|██████████| 86/86 [00:18<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.83      0.816      0.894      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    113/150       7.7G      1.231      1.214      1.589         20        640: 100%|██████████| 86/86 [00:17<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.825      0.841      0.894      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    114/150       7.7G      1.212      1.181      1.564         14        640: 100%|██████████| 86/86 [00:19<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.847      0.832      0.904      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    115/150       7.7G      1.223      1.174      1.573         15        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.89      0.823      0.908      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    116/150       7.7G       1.22      1.173      1.564         11        640: 100%|██████████| 86/86 [00:18<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.838      0.817      0.894      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    117/150       7.7G      1.206      1.147      1.559         18        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.863      0.826      0.907      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    118/150       7.7G      1.197      1.178      1.551         13        640: 100%|██████████| 86/86 [00:19<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.828      0.853      0.908      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    119/150       7.7G      1.188      1.147      1.542         17        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.88      0.826      0.913      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    120/150       7.7G      1.203      1.157      1.554         15        640: 100%|██████████| 86/86 [00:18<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.802      0.865      0.904      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    121/150       7.7G      1.199      1.134      1.549         14        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.851      0.852      0.909      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    122/150      7.75G      1.191      1.137      1.544         15        640: 100%|██████████| 86/86 [00:19<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.862      0.834      0.908      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    123/150      7.75G      1.198      1.163      1.558         12        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.807      0.867      0.906        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    124/150      7.75G      1.192      1.143      1.545         12        640: 100%|██████████| 86/86 [00:19<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.869      0.863       0.93      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    125/150      7.75G      1.205      1.145      1.555         15        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.886      0.865      0.937      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    126/150      7.75G      1.177      1.135      1.541         10        640: 100%|██████████| 86/86 [00:18<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.868      0.865      0.926      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    127/150      7.75G       1.19      1.135      1.549         12        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.884      0.829      0.922      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    128/150      7.75G       1.21      1.146      1.556         25        640: 100%|██████████| 86/86 [00:19<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.885       0.85      0.929      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    129/150      7.75G      1.154      1.111      1.522          8        640: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.893      0.832      0.932      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    130/150      7.75G      1.161      1.103      1.529         15        640: 100%|██████████| 86/86 [00:18<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.87      0.888       0.94      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    131/150      7.75G      1.179      1.119       1.54          8        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.853      0.864      0.934       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    132/150      7.77G      1.175      1.104      1.531          8        640: 100%|██████████| 86/86 [00:20<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.856      0.901      0.938      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    133/150      7.77G      1.166      1.079      1.513         20        640: 100%|██████████| 86/86 [00:17<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.881      0.895      0.939      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    134/150      7.77G      1.178       1.11      1.533         10        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.897      0.864      0.935      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    135/150      7.77G      1.173      1.102      1.528         13        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.868      0.884      0.937      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    136/150      7.77G      1.182      1.121      1.538         21        640: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.87      0.906      0.943       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    137/150      7.77G      1.168      1.112      1.532         16        640: 100%|██████████| 86/86 [00:17<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.934      0.865      0.948       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    138/150      7.77G      1.149      1.057      1.507         13        640: 100%|██████████| 86/86 [00:17<00:00,  4.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.883      0.912      0.945      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    139/150      7.77G      1.149      1.073       1.51         19        640: 100%|██████████| 86/86 [00:21<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.945      0.885      0.954      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    140/150      7.77G      1.145      1.073        1.5         17        640: 100%|██████████| 86/86 [00:21<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.917      0.891      0.954      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    141/150      7.77G      1.056     0.8697      1.454          9        640: 100%|██████████| 86/86 [00:18<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.918      0.846      0.935      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    142/150      7.77G      1.049     0.8024      1.449          7        640: 100%|██████████| 86/86 [00:17<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.919       0.88      0.946      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    143/150      7.77G      1.018     0.7581      1.434          5        640: 100%|██████████| 86/86 [00:21<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.911      0.891      0.945      0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    144/150      7.77G      1.015      0.751      1.435          7        640: 100%|██████████| 86/86 [00:20<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.929      0.885      0.953      0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    145/150      7.77G      1.023      0.751       1.43          8        640: 100%|██████████| 86/86 [00:17<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.909      0.897      0.956      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    146/150      7.77G     0.9931      0.721      1.424          7        640: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.925      0.877      0.953      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    147/150      7.77G       1.01     0.7273       1.42         10        640: 100%|██████████| 86/86 [00:20<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857       0.93      0.885      0.955       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    148/150      7.77G     0.9752     0.7041        1.4          6        640: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.929      0.884      0.953      0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    149/150      7.77G      0.991     0.7176      1.411          7        640: 100%|██████████| 86/86 [00:17<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.924      0.889      0.954      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    150/150      7.77G     0.9708     0.7186      1.404         11        640: 100%|██████████| 86/86 [00:18<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.912       0.91      0.955      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "150 epochs completed in 1.099 hours.\n",
      "Optimizer stripped from runs/detect/neudet_improved/weights/last.pt, 52.1MB\n",
      "Optimizer stripped from runs/detect/neudet_improved/weights/best.pt, 52.1MB\n",
      "\n",
      "Validating runs/detect/neudet_improved/weights/best.pt...\n",
      "Ultralytics 8.3.146 🚀 Python-3.10.10 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40337MiB)\n",
      "Model summary (fused): 92 layers, 25,843,234 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:08<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        399        857      0.913      0.906      0.955      0.684\n",
      "               crazing         25         55      0.952       0.72      0.898      0.575\n",
      "             inclusion         70        183      0.876      0.951      0.961      0.631\n",
      "               patches         47        109      0.996          1      0.995      0.822\n",
      "        pitted_surface         38         59      0.864      0.915      0.944       0.75\n",
      "       rolled-in_scale         33         64      0.923      0.932      0.972      0.696\n",
      "             scratches        221        387      0.867      0.915       0.96      0.633\n",
      "Speed: 0.2ms preprocess, 2.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Saving runs/detect/neudet_improved/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/neudet_improved\u001b[0m\n",
      "Training completed! Best model saved at: runs/detect/neudet_improved/weights/best.pt\n",
      "\n",
      "4. Running inference on test set...\n",
      "Processing 360 test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/360 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_10dh18dy69jj.jpg: 640x640 3 crazings, 107.6ms\n",
      "Speed: 2.3ms preprocess, 107.6ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 1/360 [00:02<14:57,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_17ej7vl96bai.jpg: 640x640 3 crazings, 46.3ms\n",
      "Speed: 2.5ms preprocess, 46.3ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 2/360 [00:02<06:56,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_1l6jrbqptp9x.jpg: 640x640 3 crazings, 46.1ms\n",
      "Speed: 2.2ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 3/360 [00:02<04:20,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_1olaertr3kk3.jpg: 640x640 3 crazings, 44.7ms\n",
      "Speed: 1.8ms preprocess, 44.7ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 4/360 [00:03<03:07,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_1oskoqxf9ewd.jpg: 640x640 3 crazings, 28.6ms\n",
      "Speed: 2.4ms preprocess, 28.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|▏         | 5/360 [00:03<02:21,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_2n9rfdh9adg4.jpg: 640x640 3 crazings, 46.4ms\n",
      "Speed: 3.5ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 6/360 [00:03<01:58,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_3kyz2t5jhl4d.jpg: 640x640 1 crazing, 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 7/360 [00:03<01:39,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_3zdq65hlyaa2.jpg: 640x640 6 crazings, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 8/360 [00:03<01:33,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_47ohkxigp0np.jpg: 640x640 2 crazings, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▎         | 9/360 [00:04<01:21,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_4azx7p0enj0d.jpg: 640x640 3 crazings, 46.3ms\n",
      "Speed: 2.5ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 10/360 [00:04<01:18,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_4cgo3as037hg.jpg: 640x640 4 crazings, 46.1ms\n",
      "Speed: 2.8ms preprocess, 46.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 11/360 [00:04<01:15,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_4z1mp3nqoy0k.jpg: 640x640 4 crazings, 46.2ms\n",
      "Speed: 2.9ms preprocess, 46.2ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 12/360 [00:04<01:15,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_5ooqhvxg62iy.jpg: 640x640 4 crazings, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▎         | 13/360 [00:04<01:11,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_5uktefy7i8qt.jpg: 640x640 4 crazings, 41.9ms\n",
      "Speed: 2.2ms preprocess, 41.9ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 14/360 [00:05<01:10,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_6jiq0jk4162k.jpg: 640x640 2 crazings, 23.9ms\n",
      "Speed: 1.8ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 15/360 [00:05<01:06,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_6u93bbh6rqtr.jpg: 640x640 6 crazings, 46.2ms\n",
      "Speed: 2.2ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 16/360 [00:05<01:09,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_732gf74ke843.jpg: 640x640 3 crazings, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 17/360 [00:05<01:07,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_775h60agsl6m.jpg: 640x640 1 crazing, 39.1ms\n",
      "Speed: 3.5ms preprocess, 39.1ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 18/360 [00:05<01:05,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_7o2id7ft59io.jpg: 640x640 2 crazings, 39.4ms\n",
      "Speed: 2.8ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 19/360 [00:06<01:03,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_85ea74ndv9tb.jpg: 640x640 3 crazings, 46.3ms\n",
      "Speed: 2.9ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 20/360 [00:06<01:06,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_8b9c97jkpclo.jpg: 640x640 2 crazings, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 21/360 [00:06<01:03,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_8qcns35jwjh5.jpg: 640x640 5 crazings, 43.8ms\n",
      "Speed: 3.9ms preprocess, 43.8ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 22/360 [00:06<01:06,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_8zrliunxj92k.jpg: 640x640 2 crazings, 37.1ms\n",
      "Speed: 2.7ms preprocess, 37.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▋         | 23/360 [00:06<01:03,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_aydqt0wrf3dk.jpg: 640x640 4 crazings, 46.3ms\n",
      "Speed: 3.9ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 24/360 [00:07<01:06,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_b0ynd33onkj0.jpg: 640x640 2 crazings, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 25/360 [00:07<01:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_b92iu31slkqh.jpg: 640x640 4 crazings, 46.4ms\n",
      "Speed: 2.8ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 26/360 [00:07<01:05,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_bsiz87vas0iq.jpg: 640x640 5 crazings, 32.4ms\n",
      "Speed: 3.0ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 27/360 [00:07<01:04,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_c6bqe0h5mv0k.jpg: 640x640 4 crazings, 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 28/360 [00:07<01:06,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_cla3f9s5puk6.jpg: 640x640 3 crazings, 44.3ms\n",
      "Speed: 1.9ms preprocess, 44.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 29/360 [00:08<01:07,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_cwsm75up8qki.jpg: 640x640 2 crazings, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 30/360 [00:08<01:04,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_dkw5ys9hsyrq.jpg: 640x640 2 crazings, 43.8ms\n",
      "Speed: 2.2ms preprocess, 43.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▊         | 31/360 [00:08<01:05,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_duxfqaip87q5.jpg: 640x640 2 crazings, 42.5ms\n",
      "Speed: 2.6ms preprocess, 42.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 32/360 [00:08<01:03,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_efs4b3k69oy6.jpg: 640x640 3 crazings, 46.1ms\n",
      "Speed: 2.6ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 33/360 [00:08<01:05,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_ehdmanftrc7d.jpg: 640x640 2 crazings, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 34/360 [00:08<01:01,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_ejb9hal8xhd9.jpg: 640x640 2 crazings, 46.4ms\n",
      "Speed: 3.3ms preprocess, 46.4ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 35/360 [00:09<01:02,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_f1efwmg77wdq.jpg: 640x640 2 crazings, 38.8ms\n",
      "Speed: 2.3ms preprocess, 38.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 36/360 [00:09<01:01,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_fwgeo3vciwpq.jpg: 640x640 2 crazings, 46.2ms\n",
      "Speed: 3.9ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 37/360 [00:09<01:03,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_gg7tsgqc2lz1.jpg: 640x640 2 crazings, 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 38/360 [00:09<01:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_ipkn4qozjnha.jpg: 640x640 2 crazings, 46.3ms\n",
      "Speed: 3.0ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 39/360 [00:09<01:01,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_ivslgzsm6r15.jpg: 640x640 2 crazings, 42.2ms\n",
      "Speed: 2.7ms preprocess, 42.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 40/360 [00:10<01:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_jf51r61subhv.jpg: 640x640 4 crazings, 46.2ms\n",
      "Speed: 3.9ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█▏        | 41/360 [00:10<01:03,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_jpx4663lc7cb.jpg: 640x640 3 crazings, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 42/360 [00:10<01:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_kgrz6g901ugs.jpg: 640x640 1 crazing, 46.3ms\n",
      "Speed: 2.8ms preprocess, 46.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 43/360 [00:10<00:59,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_kidwdxp6xq63.jpg: 640x640 3 crazings, 46.5ms\n",
      "Speed: 2.5ms preprocess, 46.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 44/360 [00:10<00:59,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_lh1h1tvqud7y.jpg: 640x640 3 crazings, 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▎        | 45/360 [00:11<01:02,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_p2v7ab3313rd.jpg: 640x640 1 crazing, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 46/360 [00:11<00:58,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_pc45ch3yqi5x.jpg: 640x640 3 crazings, 46.3ms\n",
      "Speed: 3.3ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 47/360 [00:11<01:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_pg7orwu8oelv.jpg: 640x640 2 crazings, 34.2ms\n",
      "Speed: 3.1ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 48/360 [00:11<00:58,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_q22hcbs0lpjl.jpg: 640x640 2 crazings, 46.1ms\n",
      "Speed: 3.6ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▎        | 49/360 [00:11<01:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_r40oh127cb2w.jpg: 640x640 2 crazings, 24.7ms\n",
      "Speed: 2.3ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 50/360 [00:12<00:57,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_repb1vdyqtrn.jpg: 640x640 2 crazings, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 51/360 [00:12<00:59,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_rreyt9rqylmv.jpg: 640x640 2 crazings, 40.2ms\n",
      "Speed: 3.7ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 52/360 [00:12<00:57,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_sleqct8ryt0y.jpg: 640x640 4 crazings, 46.3ms\n",
      "Speed: 3.0ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 53/360 [00:12<01:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_syz33pn2ui8g.jpg: 640x640 2 crazings, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 54/360 [00:12<00:57,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_tflqo93rseke.jpg: 640x640 3 crazings, 46.3ms\n",
      "Speed: 3.8ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 55/360 [00:12<00:59,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_vonbie8tg61g.jpg: 640x640 4 crazings, 32.6ms\n",
      "Speed: 3.6ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 56/360 [00:13<00:57,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_vssofcl8vkw1.jpg: 640x640 2 crazings, 46.2ms\n",
      "Speed: 2.6ms preprocess, 46.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 57/360 [00:13<00:59,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_woualnqbvy2q.jpg: 640x640 2 crazings, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 58/360 [00:13<00:57,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_xzrkabska7j3.jpg: 640x640 2 crazings, 41.1ms\n",
      "Speed: 3.6ms preprocess, 41.1ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▋        | 59/360 [00:13<00:57,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/crazing_zpd4z06qos6i.jpg: 640x640 1 crazing, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 60/360 [00:13<00:54,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_0yagqq8j32j4.jpg: 640x640 2 inclusions, 46.2ms\n",
      "Speed: 3.2ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 61/360 [00:14<00:57,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_15xiry3rxqa3.jpg: 640x640 5 inclusions, 24.4ms\n",
      "Speed: 2.9ms preprocess, 24.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 62/360 [00:14<00:56,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_1rcwpg4r35n6.jpg: 640x640 3 inclusions, 46.1ms\n",
      "Speed: 3.9ms preprocess, 46.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 63/360 [00:14<00:56,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_1x07vhx2vc7d.jpg: 640x640 4 inclusions, 32.4ms\n",
      "Speed: 3.2ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 64/360 [00:14<00:55,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_281i2l5ivmjz.jpg: 640x640 2 inclusions, 46.4ms\n",
      "Speed: 4.0ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 65/360 [00:15<01:20,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_302uvaw4djt7.jpg: 640x640 1 inclusion, 44.8ms\n",
      "Speed: 4.0ms preprocess, 44.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 66/360 [00:15<01:13,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_3jf9lqfc2oik.jpg: 640x640 2 inclusions, 31.5ms\n",
      "Speed: 2.2ms preprocess, 31.5ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▊        | 67/360 [00:15<01:07,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_3oqdhkj8y6na.jpg: 640x640 2 inclusions, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 68/360 [00:15<01:03,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_3p1426bfhu7r.jpg: 640x640 1 inclusion, 46.0ms\n",
      "Speed: 3.9ms preprocess, 46.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 69/360 [00:15<01:03,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_3vvys8s04vvg.jpg: 640x640 2 inclusions, 46.1ms\n",
      "Speed: 3.2ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 70/360 [00:16<01:02,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_40kigdojhzd6.jpg: 640x640 3 inclusions, 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 71/360 [00:16<00:58,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_4q4bm6god73g.jpg: 640x640 6 inclusions, 46.2ms\n",
      "Speed: 3.0ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 72/360 [00:16<01:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_4thvsca69hm4.jpg: 640x640 2 inclusions, 30.1ms\n",
      "Speed: 3.4ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 73/360 [00:16<00:56,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_4vlyohn19jdt.jpg: 640x640 1 inclusion, 44.8ms\n",
      "Speed: 1.9ms preprocess, 44.8ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 74/360 [00:16<00:56,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_52ad3w1xbf2q.jpg: 640x640 2 inclusions, 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 75/360 [00:17<00:54,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_57iq86i7nplv.jpg: 640x640 2 inclusions, 46.3ms\n",
      "Speed: 2.8ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 76/360 [00:17<00:55,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_6jugyyjbihvb.jpg: 640x640 2 inclusions, 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██▏       | 77/360 [00:17<00:54,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_6pbhmdz6n9ze.jpg: 640x640 4 inclusions, 44.7ms\n",
      "Speed: 1.9ms preprocess, 44.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 78/360 [00:17<00:57,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_6wymwjyrj2cj.jpg: 640x640 5 inclusions, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 79/360 [00:17<00:54,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_7m3ziv97c5ak.jpg: 640x640 3 inclusions, 46.3ms\n",
      "Speed: 3.6ms preprocess, 46.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 80/360 [00:18<00:55,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_9a25ck7bshul.jpg: 640x640 9 inclusions, 32.6ms\n",
      "Speed: 2.3ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▎       | 81/360 [00:18<00:55,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_9ajkjbwtt5ow.jpg: 640x640 2 inclusions, 46.0ms\n",
      "Speed: 2.1ms preprocess, 46.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 82/360 [00:18<00:56,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_9b7li8bzddkv.jpg: 640x640 3 inclusions, 45.3ms\n",
      "Speed: 3.1ms preprocess, 45.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 83/360 [00:18<00:57,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_b46vie796ihp.jpg: 640x640 2 inclusions, 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 84/360 [00:18<00:53,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_bsosogg3zc4y.jpg: 640x640 3 inclusions, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▎       | 85/360 [00:19<00:54,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_cejdwcamkk4a.jpg: 640x640 1 inclusion, 40.2ms\n",
      "Speed: 2.1ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 86/360 [00:19<00:52,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_de60foqabdd4.jpg: 640x640 8 inclusions, 45.0ms\n",
      "Speed: 2.6ms preprocess, 45.0ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 87/360 [00:19<00:56,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_evw7q9sodeap.jpg: 640x640 3 inclusions, 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 88/360 [00:19<01:04,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_fwa0c3r5ik3j.jpg: 640x640 2 inclusions, 46.3ms\n",
      "Speed: 2.8ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 89/360 [00:20<01:01,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_hzn08x379mix.jpg: 640x640 2 inclusions, 45.2ms\n",
      "Speed: 3.7ms preprocess, 45.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 90/360 [00:20<01:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_idikck6wsbxw.jpg: 640x640 14 inclusions, 28.2ms\n",
      "Speed: 2.6ms preprocess, 28.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 91/360 [00:20<00:59,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_inasikmjd2zn.jpg: 640x640 1 inclusion, 28.3ms\n",
      "Speed: 2.3ms preprocess, 28.3ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 92/360 [00:20<00:55,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_l7m8jtfdjo8t.jpg: 640x640 2 inclusions, 38.6ms\n",
      "Speed: 3.1ms preprocess, 38.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 93/360 [00:20<00:52,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_lbtighpwdryc.jpg: 640x640 4 inclusions, 46.4ms\n",
      "Speed: 2.7ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 94/360 [00:21<00:56,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_lxfuu7sd7emo.jpg: 640x640 1 inclusion, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▋       | 95/360 [00:21<00:55,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_m6k9wk64vw2m.jpg: 640x640 1 inclusion, 31.0ms\n",
      "Speed: 3.2ms preprocess, 31.0ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 96/360 [00:21<00:51,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_m86bi1pj70xy.jpg: 640x640 2 inclusions, 23.7ms\n",
      "Speed: 2.2ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 97/360 [00:21<00:48,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_o6qxjis1m4vn.jpg: 640x640 3 inclusions, 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 98/360 [00:21<00:51,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_o7jjkzg10zho.jpg: 640x640 3 inclusions, 25.5ms\n",
      "Speed: 2.6ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 99/360 [00:21<00:48,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_pwjouvhh1uxp.jpg: 640x640 3 inclusions, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 100/360 [00:22<00:50,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_rm36qauht3zd.jpg: 640x640 9 inclusions, 38.0ms\n",
      "Speed: 2.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 101/360 [00:22<00:51,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_rziwav5xdf0r.jpg: 640x640 1 inclusion, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 102/360 [00:22<00:51,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_sch46byenesr.jpg: 640x640 3 inclusions, 44.5ms\n",
      "Speed: 4.0ms preprocess, 44.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▊       | 103/360 [00:22<00:52,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_sns4o21ridnk.jpg: 640x640 7 inclusions, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 104/360 [00:22<00:51,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_srzgafqvx463.jpg: 640x640 2 inclusions, 43.1ms\n",
      "Speed: 3.4ms preprocess, 43.1ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 105/360 [00:23<00:50,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_sw2q3kj8hxby.jpg: 640x640 6 inclusions, 32.6ms\n",
      "Speed: 2.7ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 106/360 [00:23<00:49,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_sxy32aumo47u.jpg: 640x640 1 inclusion, 46.2ms\n",
      "Speed: 3.4ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 107/360 [00:23<00:50,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_szvm3smlj087.jpg: 640x640 11 inclusions, 44.2ms\n",
      "Speed: 2.8ms preprocess, 44.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 108/360 [00:23<00:54,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_t6yd7c8vr8ef.jpg: 640x640 4 inclusions, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 109/360 [00:24<00:54,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_t7vdv8gwsry5.jpg: 640x640 3 inclusions, 22.2ms\n",
      "Speed: 1.7ms preprocess, 22.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 110/360 [00:24<00:50,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_tn94a9peg9ty.jpg: 640x640 4 inclusions, 22.1ms\n",
      "Speed: 1.8ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 111/360 [00:24<00:47,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_ugs4jljcycf6.jpg: 640x640 7 inclusions, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 112/360 [00:24<00:46,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_uumnrb5owie4.jpg: 640x640 4 inclusions, 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███▏      | 113/360 [00:24<00:44,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_vkk4s88aozc2.jpg: 640x640 5 inclusions, 38.7ms\n",
      "Speed: 3.0ms preprocess, 38.7ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 114/360 [00:24<00:46,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_w0drex55u9az.jpg: 640x640 2 inclusions, 27.9ms\n",
      "Speed: 2.7ms preprocess, 27.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 115/360 [00:25<00:44,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_w5mtyu1ehyoj.jpg: 640x640 7 inclusions, 24.1ms\n",
      "Speed: 2.0ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 116/360 [00:25<00:44,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_xsy1ahk5gtbb.jpg: 640x640 3 inclusions, 23.9ms\n",
      "Speed: 1.8ms preprocess, 23.9ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▎      | 117/360 [00:25<00:45,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_yuc9zxnlsvup.jpg: 640x640 2 inclusions, 41.0ms\n",
      "Speed: 3.2ms preprocess, 41.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 118/360 [00:25<00:45,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_ywqvs7q6jqs9.jpg: 640x640 4 inclusions, 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 119/360 [00:25<00:45,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/inclusion_z3z0lbxitjfc.jpg: 640x640 3 inclusions, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 120/360 [00:26<00:43,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_0tasuadfdm3e.jpg: 640x640 2 inclusions, 2 patchess, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▎      | 121/360 [00:26<00:43,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_0y4zmn34y9j2.jpg: 640x640 6 patchess, 43.4ms\n",
      "Speed: 1.8ms preprocess, 43.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 122/360 [00:26<00:47,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_15hf4rlsderb.jpg: 640x640 2 patchess, 34.0ms\n",
      "Speed: 3.8ms preprocess, 34.0ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 123/360 [00:26<00:45,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_1tfm6uxs9z5w.jpg: 640x640 4 patchess, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 124/360 [00:26<00:44,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_288zcexde72k.jpg: 640x640 2 inclusions, 3 patchess, 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 125/360 [00:26<00:43,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_2wbaul76xdhq.jpg: 640x640 2 patchess, 46.3ms\n",
      "Speed: 2.7ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 126/360 [00:27<00:45,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_36xwqt0d2iaj.jpg: 640x640 3 patchess, 32.7ms\n",
      "Speed: 2.2ms preprocess, 32.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 127/360 [00:27<00:44,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_3mcmw6hbmen5.jpg: 640x640 3 patchess, 25.3ms\n",
      "Speed: 2.0ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 128/360 [00:27<00:42,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_3r2s9u2y3wnb.jpg: 640x640 3 patchess, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 129/360 [00:27<00:42,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_45xc5x2xoq51.jpg: 640x640 3 patchess, 23.6ms\n",
      "Speed: 2.4ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 130/360 [00:27<00:40,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_4h3ue5ixdu6v.jpg: 640x640 3 patchess, 43.8ms\n",
      "Speed: 2.2ms preprocess, 43.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▋      | 131/360 [00:28<00:43,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_5cmdqeiqc0r1.jpg: 640x640 1 inclusion, 5 patchess, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 132/360 [00:28<00:43,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_5ow8ra11a64i.jpg: 640x640 1 inclusion, 5 patchess, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 133/360 [00:28<00:43,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_6lrgnslt9fru.jpg: 640x640 5 patchess, 43.9ms\n",
      "Speed: 3.4ms preprocess, 43.9ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 134/360 [00:28<00:45,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_8vf0f4828naz.jpg: 640x640 4 patchess, 33.4ms\n",
      "Speed: 2.2ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 135/360 [00:28<00:43,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_91nm84ger0cx.jpg: 640x640 1 inclusion, 4 patchess, 28.5ms\n",
      "Speed: 2.2ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 136/360 [00:29<00:42,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_9n0rlexbx9xk.jpg: 640x640 5 patchess, 46.4ms\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 137/360 [00:29<00:44,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_9ur8x70ne7vm.jpg: 640x640 1 crazing, 3 patchess, 31.3ms\n",
      "Speed: 2.5ms preprocess, 31.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 138/360 [00:29<00:43,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_aqotq3daoj8u.jpg: 640x640 1 inclusion, 3 patchess, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▊      | 139/360 [00:29<00:41,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_bdtoqqdsfggk.jpg: 640x640 5 patchess, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 140/360 [00:29<00:43,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_cdhd70ccsl3t.jpg: 640x640 6 patchess, 27.3ms\n",
      "Speed: 4.0ms preprocess, 27.3ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 141/360 [00:30<00:43,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_d8aiebj8ascc.jpg: 640x640 3 patchess, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 142/360 [00:30<00:59,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_d8yg57mw9qpq.jpg: 640x640 2 patchess, 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 143/360 [00:30<00:52,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_dg4z47c06nwl.jpg: 640x640 1 inclusion, 4 patchess, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 144/360 [00:30<00:47,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_ejj49mcyk0fc.jpg: 640x640 3 patchess, 46.4ms\n",
      "Speed: 4.0ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 145/360 [00:31<00:46,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_ftnu25avxym6.jpg: 640x640 1 inclusion, 5 patchess, 33.4ms\n",
      "Speed: 3.4ms preprocess, 33.4ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 146/360 [00:31<00:45,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_fw6qw18698je.jpg: 640x640 2 patchess, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 147/360 [00:31<00:42,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_fxb41hiknd5z.jpg: 640x640 2 patchess, 23.5ms\n",
      "Speed: 2.4ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 148/360 [00:31<00:40,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_g4iy6molvuyh.jpg: 640x640 1 patches, 23.9ms\n",
      "Speed: 1.8ms preprocess, 23.9ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████▏     | 149/360 [00:31<00:39,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_gb00o5e9v9iq.jpg: 640x640 1 patches, 46.3ms\n",
      "Speed: 3.4ms preprocess, 46.3ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 150/360 [00:31<00:39,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_gbgrsqmdrs1q.jpg: 640x640 3 patchess, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 151/360 [00:32<00:39,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_hvg2f9pslnt8.jpg: 640x640 1 patches, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 152/360 [00:32<00:37,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_i48o6vkh1t5i.jpg: 640x640 2 patchess, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▎     | 153/360 [00:32<00:36,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_iwo4v03083ua.jpg: 640x640 3 patchess, 23.9ms\n",
      "Speed: 1.9ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 154/360 [00:32<00:36,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_jaedhg7nvf1b.jpg: 640x640 1 inclusion, 4 patchess, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 155/360 [00:32<00:36,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_jk3uiyil69li.jpg: 640x640 3 patchess, 46.5ms\n",
      "Speed: 2.5ms preprocess, 46.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 156/360 [00:33<00:38,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_kaesrc87erv1.jpg: 640x640 3 patchess, 34.6ms\n",
      "Speed: 3.2ms preprocess, 34.6ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▎     | 157/360 [00:33<00:38,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_kb1arnme1spe.jpg: 640x640 3 patchess, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 158/360 [00:33<00:37,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_kb5gkh2beuxq.jpg: 640x640 1 inclusion, 6 patchess, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 159/360 [00:33<00:37,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_kzlcnrmtrgka.jpg: 640x640 1 inclusion, 3 patchess, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 160/360 [00:33<00:36,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_liu3fby77vhe.jpg: 640x640 5 patchess, 46.3ms\n",
      "Speed: 2.6ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 161/360 [00:34<00:38,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_ln6m20zrzkyj.jpg: 640x640 1 inclusion, 3 patchess, 32.4ms\n",
      "Speed: 3.5ms preprocess, 32.4ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 162/360 [00:34<00:38,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_m4yrlad6jske.jpg: 640x640 4 patchess, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 163/360 [00:34<00:36,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_mhianbrqjnzr.jpg: 640x640 1 patches, 1 pitted_surface, 26.9ms\n",
      "Speed: 2.3ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 164/360 [00:34<00:35,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_mivnz86yp1n6.jpg: 640x640 1 patches, 23.5ms\n",
      "Speed: 2.2ms preprocess, 23.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 165/360 [00:34<00:33,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_mjw2op2jhhki.jpg: 640x640 1 crazing, 2 inclusions, 4 patchess, 23.8ms\n",
      "Speed: 2.0ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 166/360 [00:34<00:34,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_njbr8gv81ux8.jpg: 640x640 3 patchess, 46.3ms\n",
      "Speed: 2.2ms preprocess, 46.3ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▋     | 167/360 [00:35<00:35,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_oe540cmqs9jl.jpg: 640x640 2 patchess, 34.7ms\n",
      "Speed: 2.2ms preprocess, 34.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 168/360 [00:35<00:35,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_oukb1nav4mn1.jpg: 640x640 5 patchess, 31.4ms\n",
      "Speed: 2.9ms preprocess, 31.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 169/360 [00:35<00:35,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_pqy5o7h31qzn.jpg: 640x640 1 inclusion, 3 patchess, 28.8ms\n",
      "Speed: 3.3ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 170/360 [00:35<00:34,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_stny2m983f49.jpg: 640x640 7 patchess, 46.4ms\n",
      "Speed: 2.3ms preprocess, 46.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 171/360 [00:35<00:37,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_t3mamuxm4cc5.jpg: 640x640 3 patchess, 30.3ms\n",
      "Speed: 2.5ms preprocess, 30.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 172/360 [00:36<00:35,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_ti5x5c6s1yfc.jpg: 640x640 4 patchess, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 173/360 [00:36<00:34,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_tyegl43z2dfk.jpg: 640x640 1 inclusion, 4 patchess, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 174/360 [00:36<00:34,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_vdefwh2jcr89.jpg: 640x640 4 patchess, 46.4ms\n",
      "Speed: 3.2ms preprocess, 46.4ms inference, 13.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▊     | 175/360 [00:36<00:35,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_vkihok1qbc3m.jpg: 640x640 3 patchess, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 176/360 [00:36<00:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_vpgdq1m3awso.jpg: 640x640 3 patchess, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 177/360 [00:36<00:33,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_wd2qwbkvz67d.jpg: 640x640 2 patchess, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 178/360 [00:37<00:32,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_zhqw9k3hink5.jpg: 640x640 3 patchess, 46.2ms\n",
      "Speed: 3.7ms preprocess, 46.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 179/360 [00:37<00:34,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/patches_ztv1nbg3si8o.jpg: 640x640 6 patchess, 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 180/360 [00:37<00:34,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_0791hph2dgxh.jpg: 640x640 1 pitted_surface, 30.7ms\n",
      "Speed: 3.6ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 181/360 [00:37<00:33,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_0m689edhjt29.jpg: 640x640 3 pitted_surfaces, 23.8ms\n",
      "Speed: 2.6ms preprocess, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 182/360 [00:37<00:32,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_0u3vcbeubcph.jpg: 640x640 1 pitted_surface, 46.5ms\n",
      "Speed: 3.5ms preprocess, 46.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 183/360 [00:38<00:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_1r0qpasqmzw0.jpg: 640x640 4 patchess, 1 pitted_surface, 30.2ms\n",
      "Speed: 2.9ms preprocess, 30.2ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 184/360 [00:38<00:33,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_2sjmwmlfme86.jpg: 640x640 3 pitted_surfaces, 30.5ms\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████▏    | 185/360 [00:38<00:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_2u8v6ntqhbm0.jpg: 640x640 1 pitted_surface, 44.3ms\n",
      "Speed: 1.8ms preprocess, 44.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 186/360 [00:38<00:33,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_481omjbbtglu.jpg: 640x640 3 pitted_surfaces, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 187/360 [00:38<00:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_4koeu0ftmzma.jpg: 640x640 2 pitted_surfaces, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 188/360 [00:39<00:31,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_5numgmw0k7fy.jpg: 640x640 1 pitted_surface, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▎    | 189/360 [00:39<00:30,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_5qtom70x5sdn.jpg: 640x640 (no detections), 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_6uixm3hdso7i.jpg: 640x640 1 patches, 2 pitted_surfaces, 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 191/360 [00:39<00:26,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_7x0a1ec1fezk.jpg: 640x640 2 patchess, 2 pitted_surfaces, 33.0ms\n",
      "Speed: 2.4ms preprocess, 33.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 192/360 [00:39<00:27,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_7zowcxup1k1d.jpg: 640x640 1 pitted_surface, 24.4ms\n",
      "Speed: 2.1ms preprocess, 24.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▎    | 193/360 [00:39<00:27,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_7zrb80br9pgp.jpg: 640x640 1 inclusion, 1 pitted_surface, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 194/360 [00:39<00:27,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_8jqb3gidote3.jpg: 640x640 1 inclusion, 1 pitted_surface, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 195/360 [00:40<00:27,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_8pbw0oahu5bk.jpg: 640x640 2 pitted_surfaces, 24.1ms\n",
      "Speed: 2.1ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 196/360 [00:40<00:27,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_9jpfgzz4gp6i.jpg: 640x640 1 pitted_surface, 44.2ms\n",
      "Speed: 1.7ms preprocess, 44.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 197/360 [00:40<00:29,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_a3jicq1vp3gw.jpg: 640x640 1 patches, 4 pitted_surfaces, 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 198/360 [00:40<00:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_a49w61o5i8c1.jpg: 640x640 1 pitted_surface, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 199/360 [00:40<00:28,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_a4cjsp76wts9.jpg: 640x640 1 pitted_surface, 23.8ms\n",
      "Speed: 1.9ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 200/360 [00:41<00:27,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_a6q2nm8x4e54.jpg: 640x640 1 pitted_surface, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 201/360 [00:41<00:27,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_aakhjirui0b4.jpg: 640x640 1 patches, 1 pitted_surface, 29.2ms\n",
      "Speed: 2.7ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 202/360 [00:41<00:27,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_b0oqzz0lwkep.jpg: 640x640 1 patches, 1 pitted_surface, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▋    | 203/360 [00:41<00:27,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_bqtl6g325yzi.jpg: 640x640 1 pitted_surface, 44.0ms\n",
      "Speed: 3.7ms preprocess, 44.0ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 204/360 [00:41<00:28,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_cfosaocno4er.jpg: 640x640 1 patches, 1 pitted_surface, 34.2ms\n",
      "Speed: 3.7ms preprocess, 34.2ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 205/360 [00:41<00:28,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_eilmd3vklu4u.jpg: 640x640 1 pitted_surface, 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 206/360 [00:42<00:27,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_eirnvw3yi6yy.jpg: 640x640 1 patches, 1 pitted_surface, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▊    | 207/360 [00:42<00:26,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ekw4ki9h5arf.jpg: 640x640 1 pitted_surface, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 208/360 [00:42<00:26,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_et53275x7uht.jpg: 640x640 1 pitted_surface, 26.8ms\n",
      "Speed: 3.2ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 209/360 [00:42<00:25,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_fbjf8nyjpxb6.jpg: 640x640 1 patches, 1 pitted_surface, 23.5ms\n",
      "Speed: 2.0ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 210/360 [00:42<00:25,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_fo53jop5p7cb.jpg: 640x640 2 pitted_surfaces, 43.6ms\n",
      "Speed: 3.8ms preprocess, 43.6ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▊    | 211/360 [00:42<00:26,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_grfjqwffnq60.jpg: 640x640 1 pitted_surface, 30.1ms\n",
      "Speed: 2.8ms preprocess, 30.1ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 212/360 [00:43<00:26,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_h1g2phe0g4b6.jpg: 640x640 2 pitted_surfaces, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 213/360 [00:43<00:25,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ifcpnqws07yb.jpg: 640x640 1 inclusion, 2 patchess, 2 pitted_surfaces, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 214/360 [00:43<00:26,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_l7ml5ds8ktjg.jpg: 640x640 2 pitted_surfaces, 51.1ms\n",
      "Speed: 2.1ms preprocess, 51.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 215/360 [00:43<00:27,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_lxxhngilvoum.jpg: 640x640 1 patches, 1 pitted_surface, 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 216/360 [00:43<00:27,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_m1fnvw0aguv2.jpg: 640x640 1 patches, 1 pitted_surface, 23.8ms\n",
      "Speed: 1.9ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 217/360 [00:44<00:26,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_n9i2a31q97gd.jpg: 640x640 1 inclusion, 1 pitted_surface, 27.3ms\n",
      "Speed: 2.4ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 218/360 [00:44<00:25,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_o4was3jgm2el.jpg: 640x640 1 pitted_surface, 45.3ms\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 219/360 [00:44<00:26,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ofrbcsiaq9rg.jpg: 640x640 1 pitted_surface, 30.4ms\n",
      "Speed: 3.0ms preprocess, 30.4ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 220/360 [00:44<00:25,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ogc3k8xgxuhg.jpg: 640x640 3 patchess, 1 pitted_surface, 27.3ms\n",
      "Speed: 2.5ms preprocess, 27.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████▏   | 221/360 [00:44<00:25,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_p010fd9ruh0x.jpg: 640x640 2 patchess, 1 pitted_surface, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 222/360 [00:44<00:24,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_q7pxexjuyn9u.jpg: 640x640 1 pitted_surface, 46.4ms\n",
      "Speed: 4.0ms preprocess, 46.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 223/360 [00:45<00:37,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_qxgur7z0tuj0.jpg: 640x640 1 pitted_surface, 31.9ms\n",
      "Speed: 2.7ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 224/360 [00:45<00:32,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_rxoivotqcz7w.jpg: 640x640 2 pitted_surfaces, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▎   | 225/360 [00:45<00:29,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_std3bkllbzch.jpg: 640x640 1 pitted_surface, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 226/360 [00:45<00:26,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_t6f3v4gcgiqz.jpg: 640x640 1 patches, 1 pitted_surface, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 14.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 227/360 [00:46<00:27,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_thgtx8uw7lm0.jpg: 640x640 2 pitted_surfaces, 30.4ms\n",
      "Speed: 2.1ms preprocess, 30.4ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 228/360 [00:46<00:26,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_tn8acypd3jlo.jpg: 640x640 1 pitted_surface, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▎   | 229/360 [00:46<00:24,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_tq062njiuz7i.jpg: 640x640 1 patches, 1 pitted_surface, 22.0ms\n",
      "Speed: 1.8ms preprocess, 22.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 230/360 [00:46<00:23,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_tybc6bbq01n8.jpg: 640x640 2 pitted_surfaces, 22.0ms\n",
      "Speed: 1.8ms preprocess, 22.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 231/360 [00:46<00:22,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_uvymq9nylpqs.jpg: 640x640 1 pitted_surface, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 232/360 [00:47<00:21,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_v7xoxbhtz0db.jpg: 640x640 2 pitted_surfaces, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 233/360 [00:47<00:20,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_w2dg56uuj50y.jpg: 640x640 1 patches, 1 pitted_surface, 22.3ms\n",
      "Speed: 1.8ms preprocess, 22.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 234/360 [00:47<00:20,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_x84tr5onyaet.jpg: 640x640 1 pitted_surface, 42.3ms\n",
      "Speed: 3.3ms preprocess, 42.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 235/360 [00:47<00:21,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_xbhlx5k0jfv3.jpg: 640x640 1 pitted_surface, 38.1ms\n",
      "Speed: 3.7ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 236/360 [00:47<00:21,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_xf7qaa0dkvi7.jpg: 640x640 3 patchess, 2 pitted_surfaces, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 237/360 [00:47<00:23,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ysvko081urnu.jpg: 640x640 1 pitted_surface, 38.1ms\n",
      "Speed: 1.9ms preprocess, 38.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 238/360 [00:48<00:23,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_ywwzbhzmpcu6.jpg: 640x640 2 pitted_surfaces, 28.0ms\n",
      "Speed: 2.6ms preprocess, 28.0ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▋   | 239/360 [00:48<00:23,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/pitted_surface_zkxu7y3y9qfm.jpg: 640x640 1 inclusion, 2 pitted_surfaces, 46.3ms\n",
      "Speed: 2.6ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 240/360 [00:48<00:24,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_0iu14b9sngv8.jpg: 640x640 2 rolled-in_scales, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 241/360 [00:48<00:23,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_0kuzivzju9ei.jpg: 640x640 2 rolled-in_scales, 46.1ms\n",
      "Speed: 4.3ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 242/360 [00:48<00:24,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_0vim0g5lswym.jpg: 640x640 4 rolled-in_scales, 39.2ms\n",
      "Speed: 1.9ms preprocess, 39.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 243/360 [00:49<00:24,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_0x57iehyk1tn.jpg: 640x640 2 rolled-in_scales, 24.8ms\n",
      "Speed: 3.8ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 244/360 [00:49<00:23,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_2bhk6es9p7cy.jpg: 640x640 2 rolled-in_scales, 46.2ms\n",
      "Speed: 3.5ms preprocess, 46.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 245/360 [00:49<00:23,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_2s958kbfwj68.jpg: 640x640 3 rolled-in_scales, 31.8ms\n",
      "Speed: 3.0ms preprocess, 31.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 246/360 [00:49<00:22,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_3ckrhac28z7m.jpg: 640x640 4 rolled-in_scales, 46.3ms\n",
      "Speed: 2.5ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▊   | 247/360 [00:49<00:23,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_3q4qjrwm7yo2.jpg: 640x640 3 rolled-in_scales, 44.8ms\n",
      "Speed: 2.2ms preprocess, 44.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 248/360 [00:50<00:23,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_3uy6y52wixuc.jpg: 640x640 5 rolled-in_scales, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 249/360 [00:50<00:23,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_70951t3xfau3.jpg: 640x640 2 rolled-in_scales, 30.7ms\n",
      "Speed: 3.0ms preprocess, 30.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 250/360 [00:50<00:22,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_76j1aun0ijm4.jpg: 640x640 2 rolled-in_scales, 23.4ms\n",
      "Speed: 2.2ms preprocess, 23.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 251/360 [00:50<00:20,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_7cc9llqwlx60.jpg: 640x640 4 rolled-in_scales, 46.0ms\n",
      "Speed: 2.6ms preprocess, 46.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 252/360 [00:50<00:22,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_7f786w33ynzz.jpg: 640x640 3 rolled-in_scales, 41.5ms\n",
      "Speed: 2.9ms preprocess, 41.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 253/360 [00:51<00:22,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_7zzufmnpbjli.jpg: 640x640 2 rolled-in_scales, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 254/360 [00:51<00:21,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_8f41u2r4kpha.jpg: 640x640 2 rolled-in_scales, 46.3ms\n",
      "Speed: 3.6ms preprocess, 46.3ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 255/360 [00:51<00:21,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_8orlbohsrwoj.jpg: 640x640 4 rolled-in_scales, 32.5ms\n",
      "Speed: 2.2ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 256/360 [00:51<00:20,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_9wqogo5ajioz.jpg: 640x640 2 rolled-in_scales, 46.2ms\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████▏  | 257/360 [00:52<00:21,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_b686qc6z933u.jpg: 640x640 7 rolled-in_scales, 44.1ms\n",
      "Speed: 2.3ms preprocess, 44.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 258/360 [00:52<00:22,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_dds7t20jxocg.jpg: 640x640 4 rolled-in_scales, 37.9ms\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 259/360 [00:52<00:22,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_du7rqxpzrjcw.jpg: 640x640 5 rolled-in_scales, 25.2ms\n",
      "Speed: 3.4ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 260/360 [00:52<00:20,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_e2og62yreqee.jpg: 640x640 3 rolled-in_scales, 43.7ms\n",
      "Speed: 3.1ms preprocess, 43.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▎  | 261/360 [00:52<00:20,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_el0ux348wfqk.jpg: 640x640 2 rolled-in_scales, 30.1ms\n",
      "Speed: 2.8ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 262/360 [00:53<00:19,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_etolrv5vywyx.jpg: 640x640 4 rolled-in_scales, 46.4ms\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 263/360 [00:53<00:20,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_fhbtun6no2yh.jpg: 640x640 1 rolled-in_scale, 44.6ms\n",
      "Speed: 2.6ms preprocess, 44.6ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 264/360 [00:53<00:20,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ga3vwwsnbdto.jpg: 640x640 2 rolled-in_scales, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▎  | 265/360 [00:53<00:19,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_getul7390a5q.jpg: 640x640 4 rolled-in_scales, 46.6ms\n",
      "Speed: 2.3ms preprocess, 46.6ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 266/360 [00:53<00:19,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_gqzw2p3lgpyf.jpg: 640x640 3 rolled-in_scales, 24.5ms\n",
      "Speed: 3.9ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 267/360 [00:54<00:18,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_gtxhz6ihkm5c.jpg: 640x640 4 rolled-in_scales, 46.1ms\n",
      "Speed: 3.3ms preprocess, 46.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 268/360 [00:54<00:19,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ha16jnmn8g1x.jpg: 640x640 2 rolled-in_scales, 46.0ms\n",
      "Speed: 3.4ms preprocess, 46.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 269/360 [00:54<00:19,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_hlf6dymfrn5t.jpg: 640x640 3 rolled-in_scales, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 270/360 [00:54<00:18,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ieuqgblk2y71.jpg: 640x640 3 rolled-in_scales, 39.5ms\n",
      "Speed: 3.8ms preprocess, 39.5ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 271/360 [00:54<00:18,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_iv0gbbjok368.jpg: 640x640 3 rolled-in_scales, 46.3ms\n",
      "Speed: 3.3ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 272/360 [00:55<00:18,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_j2vexehx865o.jpg: 640x640 1 rolled-in_scale, 38.8ms\n",
      "Speed: 2.1ms preprocess, 38.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 273/360 [00:55<00:17,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_km40nq6gqoei.jpg: 640x640 4 rolled-in_scales, 46.5ms\n",
      "Speed: 3.3ms preprocess, 46.5ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 274/360 [00:55<00:18,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_kpr2pp7d4h6z.jpg: 640x640 2 rolled-in_scales, 41.1ms\n",
      "Speed: 4.0ms preprocess, 41.1ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▋  | 275/360 [00:55<00:18,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_l1ee4mivom7j.jpg: 640x640 2 rolled-in_scales, 27.8ms\n",
      "Speed: 2.4ms preprocess, 27.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 276/360 [00:55<00:16,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_lcxxq4xzjjjv.jpg: 640x640 2 rolled-in_scales, 46.3ms\n",
      "Speed: 3.0ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 277/360 [00:56<00:16,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_lez9dfazorsf.jpg: 640x640 4 rolled-in_scales, 42.6ms\n",
      "Speed: 3.7ms preprocess, 42.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 278/360 [00:56<00:16,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_m4whwb71q954.jpg: 640x640 4 rolled-in_scales, 46.3ms\n",
      "Speed: 2.4ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 279/360 [00:56<00:17,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_meosp7em1j5r.jpg: 640x640 3 rolled-in_scales, 41.7ms\n",
      "Speed: 3.9ms preprocess, 41.7ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 280/360 [00:56<00:17,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_o4knmteqma96.jpg: 640x640 3 rolled-in_scales, 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 281/360 [00:56<00:16,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ouuu5q4h8rzk.jpg: 640x640 2 rolled-in_scales, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 282/360 [00:57<00:15,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_p4jop5hs9v4b.jpg: 640x640 1 rolled-in_scale, 36.3ms\n",
      "Speed: 3.9ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▊  | 283/360 [00:57<00:15,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_p4nicn8l1h29.jpg: 640x640 2 rolled-in_scales, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 284/360 [00:57<00:15,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_p97e5wknnruu.jpg: 640x640 2 rolled-in_scales, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 285/360 [00:57<00:14,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_pspfogtivujq.jpg: 640x640 3 rolled-in_scales, 46.2ms\n",
      "Speed: 3.2ms preprocess, 46.2ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 286/360 [00:57<00:14,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_qihq88bnis8p.jpg: 640x640 2 rolled-in_scales, 32.3ms\n",
      "Speed: 3.1ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 287/360 [00:58<00:14,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_rih06zkuswow.jpg: 640x640 4 rolled-in_scales, 46.2ms\n",
      "Speed: 3.7ms preprocess, 46.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 288/360 [00:58<00:14,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_rrog4wmgytar.jpg: 640x640 2 rolled-in_scales, 42.3ms\n",
      "Speed: 3.1ms preprocess, 42.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 289/360 [00:58<00:15,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_s0kq86ypd42s.jpg: 640x640 5 rolled-in_scales, 30.5ms\n",
      "Speed: 3.3ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 290/360 [00:58<00:14,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_stbg0gmm3ua7.jpg: 640x640 3 rolled-in_scales, 46.2ms\n",
      "Speed: 3.5ms preprocess, 46.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 291/360 [00:59<00:14,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_sxis56iti5b5.jpg: 640x640 3 rolled-in_scales, 32.4ms\n",
      "Speed: 3.8ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 292/360 [00:59<00:13,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_t1e4ud7ov4us.jpg: 640x640 3 rolled-in_scales, 46.1ms\n",
      "Speed: 3.7ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████▏ | 293/360 [00:59<00:13,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_t36oud0t7x0u.jpg: 640x640 5 rolled-in_scales, 38.4ms\n",
      "Speed: 1.9ms preprocess, 38.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 294/360 [00:59<00:14,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_urw7tm6r6ocj.jpg: 640x640 2 rolled-in_scales, 25.5ms\n",
      "Speed: 1.9ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 295/360 [00:59<00:13,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_vu48xtcxd8b5.jpg: 640x640 2 rolled-in_scales, 46.1ms\n",
      "Speed: 2.3ms preprocess, 46.1ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 296/360 [01:00<00:13,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_xodglivvg16c.jpg: 640x640 3 rolled-in_scales, 44.7ms\n",
      "Speed: 2.9ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▎ | 297/360 [01:00<00:12,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_y7y06kwlntbx.jpg: 640x640 2 rolled-in_scales, 46.2ms\n",
      "Speed: 3.8ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 298/360 [01:00<00:12,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ydh4f8c1s38d.jpg: 640x640 1 rolled-in_scale, 23.9ms\n",
      "Speed: 1.9ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 299/360 [01:00<00:11,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/rolled-in_scale_ygxjxw239o5y.jpg: 640x640 2 rolled-in_scales, 46.3ms\n",
      "Speed: 2.4ms preprocess, 46.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 300/360 [01:00<00:11,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_064v79hyzr6w.jpg: 640x640 1 pitted_surface, 2 scratchess, 32.1ms\n",
      "Speed: 2.5ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▎ | 301/360 [01:00<00:11,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_1krmfax331eu.jpg: 640x640 5 scratchess, 46.4ms\n",
      "Speed: 3.0ms preprocess, 46.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 302/360 [01:01<00:11,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_2roolxtb4al4.jpg: 640x640 2 scratchess, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 303/360 [01:01<00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_2vr3o5s11pfw.jpg: 640x640 1 scratches, 43.3ms\n",
      "Speed: 2.4ms preprocess, 43.3ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 304/360 [01:01<00:10,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_2vsl4y7brcrf.jpg: 640x640 7 scratchess, 38.8ms\n",
      "Speed: 3.6ms preprocess, 38.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 305/360 [01:01<00:10,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_3h4hvwaw3nvf.jpg: 640x640 6 scratchess, 46.0ms\n",
      "Speed: 3.8ms preprocess, 46.0ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 306/360 [01:02<00:15,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_3tdaalmhzmby.jpg: 640x640 3 scratchess, 46.0ms\n",
      "Speed: 2.9ms preprocess, 46.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 307/360 [01:02<00:13,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_3wg7jujqwwu1.jpg: 640x640 1 scratches, 44.9ms\n",
      "Speed: 2.4ms preprocess, 44.9ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 308/360 [01:02<00:12,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_46th8j7ror33.jpg: 640x640 4 scratchess, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 309/360 [01:02<00:11,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_4nsmu3yr9ag0.jpg: 640x640 4 scratchess, 46.2ms\n",
      "Speed: 2.9ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 310/360 [01:03<00:11,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_524kxigden3y.jpg: 640x640 3 scratchess, 27.3ms\n",
      "Speed: 2.6ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▋ | 311/360 [01:03<00:10,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_57vrx8iscvrz.jpg: 640x640 1 inclusion, 3 scratchess, 46.4ms\n",
      "Speed: 2.3ms preprocess, 46.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 312/360 [01:03<00:10,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_634mk6h9wlwc.jpg: 640x640 3 scratchess, 42.2ms\n",
      "Speed: 4.1ms preprocess, 42.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 313/360 [01:03<00:10,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_6tt5ntx30h93.jpg: 640x640 2 scratchess, 32.3ms\n",
      "Speed: 2.3ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 314/360 [01:03<00:09,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_80cn3h7h4te7.jpg: 640x640 4 scratchess, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 315/360 [01:04<00:09,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_870980r6e22z.jpg: 640x640 3 scratchess, 46.1ms\n",
      "Speed: 3.4ms preprocess, 46.1ms inference, 11.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 316/360 [01:04<00:08,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_89cak71hgcoa.jpg: 640x640 2 inclusions, 1 scratches, 46.5ms\n",
      "Speed: 3.1ms preprocess, 46.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 317/360 [01:04<00:09,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_90eqou8tylfi.jpg: 640x640 2 scratchess, 36.8ms\n",
      "Speed: 1.8ms preprocess, 36.8ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 318/360 [01:04<00:08,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_9lusknxh0znl.jpg: 640x640 2 scratchess, 32.9ms\n",
      "Speed: 2.1ms preprocess, 32.9ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▊ | 319/360 [01:04<00:08,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ah42zas00hig.jpg: 640x640 1 inclusion, 4 scratchess, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 320/360 [01:05<00:08,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_b11vgcovrwkr.jpg: 640x640 2 scratchess, 43.6ms\n",
      "Speed: 3.4ms preprocess, 43.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 321/360 [01:05<00:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ba19dfyrxueu.jpg: 640x640 3 scratchess, 42.3ms\n",
      "Speed: 1.9ms preprocess, 42.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 322/360 [01:05<00:07,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_cgalne8ylsp3.jpg: 640x640 1 inclusion, 4 scratchess, 30.6ms\n",
      "Speed: 2.8ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 323/360 [01:05<00:07,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ctv6fhhv74n4.jpg: 640x640 1 inclusion, 2 scratchess, 46.5ms\n",
      "Speed: 3.3ms preprocess, 46.5ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 324/360 [01:05<00:07,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_e4gstlikcsoc.jpg: 640x640 4 scratchess, 40.4ms\n",
      "Speed: 3.2ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 325/360 [01:06<00:06,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ecd9mw6z89yz.jpg: 640x640 3 scratchess, 46.2ms\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 326/360 [01:06<00:07,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_f1jsn57mjoc8.jpg: 640x640 3 scratchess, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 327/360 [01:06<00:07,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_feor26gs2e3n.jpg: 640x640 1 inclusion, 2 scratchess, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 328/360 [01:06<00:06,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_g55q3s264fg7.jpg: 640x640 2 scratchess, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████▏| 329/360 [01:06<00:06,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_hcjl993tsr3l.jpg: 640x640 5 scratchess, 39.0ms\n",
      "Speed: 2.5ms preprocess, 39.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 330/360 [01:07<00:05,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_hkz8o4lp3m83.jpg: 640x640 1 scratches, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 331/360 [01:07<00:05,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_hva2z9mgm3hb.jpg: 640x640 3 scratchess, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 332/360 [01:07<00:05,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_iaebj2srv2it.jpg: 640x640 2 scratchess, 46.2ms\n",
      "Speed: 3.5ms preprocess, 46.2ms inference, 9.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▎| 333/360 [01:07<00:05,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_iugu3tns77jp.jpg: 640x640 1 scratches, 38.4ms\n",
      "Speed: 2.3ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_jikgb7e43kkv.jpg: 640x640 2 inclusions, 3 scratchess, 43.3ms\n",
      "Speed: 1.6ms preprocess, 43.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 335/360 [01:08<00:04,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_jxfygjksw5zq.jpg: 640x640 4 scratchess, 32.5ms\n",
      "Speed: 3.7ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 336/360 [01:08<00:04,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_mpy90l52e4if.jpg: 640x640 1 inclusion, 3 scratchess, 46.3ms\n",
      "Speed: 3.8ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▎| 337/360 [01:08<00:04,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ngy8waxl435h.jpg: 640x640 2 scratchess, 44.7ms\n",
      "Speed: 4.0ms preprocess, 44.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 338/360 [01:08<00:04,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_noeqpty165qe.jpg: 640x640 2 scratchess, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 339/360 [01:08<00:04,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_obdzzi11zmvi.jpg: 640x640 3 scratchess, 46.3ms\n",
      "Speed: 3.6ms preprocess, 46.3ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 340/360 [01:09<00:03,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_p6s87y88epil.jpg: 640x640 3 scratchess, 32.1ms\n",
      "Speed: 2.8ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 341/360 [01:09<00:03,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_pq5digexy5te.jpg: 640x640 1 inclusion, 1 scratches, 46.7ms\n",
      "Speed: 3.9ms preprocess, 46.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 342/360 [01:09<00:03,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_pr527tdothx0.jpg: 640x640 3 scratchess, 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 343/360 [01:09<00:03,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_qoodom5ilk08.jpg: 640x640 4 scratchess, 37.8ms\n",
      "Speed: 2.8ms preprocess, 37.8ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 344/360 [01:09<00:03,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_rqy4qbog6sja.jpg: 640x640 1 inclusion, 2 scratchess, 38.9ms\n",
      "Speed: 1.9ms preprocess, 38.9ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 345/360 [01:10<00:03,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_rutyo57xsulb.jpg: 640x640 2 scratchess, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 346/360 [01:10<00:02,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_scl2kvgq9nut.jpg: 640x640 2 inclusions, 2 scratchess, 46.1ms\n",
      "Speed: 3.8ms preprocess, 46.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▋| 347/360 [01:10<00:02,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_sgtt7cusxd8m.jpg: 640x640 1 scratches, 44.4ms\n",
      "Speed: 3.0ms preprocess, 44.4ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 348/360 [01:10<00:02,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_tjd39622bnu8.jpg: 640x640 4 scratchess, 34.5ms\n",
      "Speed: 3.7ms preprocess, 34.5ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 349/360 [01:10<00:02,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_twrko6brqsrt.jpg: 640x640 5 scratchess, 46.3ms\n",
      "Speed: 2.7ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 350/360 [01:11<00:02,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_u095et0z44w9.jpg: 640x640 4 scratchess, 36.6ms\n",
      "Speed: 3.8ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 351/360 [01:11<00:01,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_v3t9bcgq9uf7.jpg: 640x640 1 inclusion, 3 scratchess, 43.7ms\n",
      "Speed: 2.8ms preprocess, 43.7ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 352/360 [01:11<00:01,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_v5trsuzb6ra9.jpg: 640x640 3 scratchess, 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 14.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 353/360 [01:11<00:01,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_v7o5ceg9crfr.jpg: 640x640 1 inclusion, 3 scratchess, 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 354/360 [01:11<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_vk1wwcn33wfj.jpg: 640x640 1 scratches, 46.2ms\n",
      "Speed: 3.9ms preprocess, 46.2ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▊| 355/360 [01:12<00:01,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_vwf2dntpiqjw.jpg: 640x640 4 scratchess, 43.9ms\n",
      "Speed: 3.2ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 356/360 [01:12<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_wlaunrppwfmf.jpg: 640x640 1 scratches, 46.3ms\n",
      "Speed: 3.8ms preprocess, 46.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 357/360 [01:12<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_y4p3ayz33k2y.jpg: 640x640 2 scratchess, 25.0ms\n",
      "Speed: 2.5ms preprocess, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 358/360 [01:12<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_ymyqf6larhda.jpg: 640x640 3 scratchess, 46.3ms\n",
      "Speed: 3.9ms preprocess, 46.3ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 359/360 [01:12<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/jp/LCS/Machine Learning/Final Project/test/scratches_z81i6li74hhg.jpg: 640x640 1 inclusion, 1 scratches, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 11.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 360/360 [01:13<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved CSV to ./submission_Yolo_1.csv\n",
      "[INFO] Saved annotated images to output_visualizations/\n",
      "\n",
      "=== Detection Statistics ===\n",
      "Total images processed: 360\n",
      "Images with detections: 358\n",
      "Images without detections: 2\n",
      "Detection rate: 99.4%\n",
      "\n",
      "Class distribution:\n",
      "  patches: 69\n",
      "  inclusion: 63\n",
      "  crazing: 60\n",
      "  rolled-in_scale: 60\n",
      "  scratches: 56\n",
      "  pitted_surface: 50\n",
      "\n",
      "=== Training and Inference Complete! ===\n",
      "Submission file saved to: ./submission_Yolo_1.csv\n",
      "Check the runs/detect/neudet_improved/ folder for training logs and metrics.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations import BboxParams\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "CONF_THRESHOLD = 0.25\n",
    "IOU_THRESHOLD = 0.45\n",
    "IMG_SIZE = 640\n",
    "\n",
    "# Dataset paths\n",
    "TRAIN_IMG_ROOT = \"./train_images\"\n",
    "TRAIN_ANN_ROOT = \"./train_annotations\"\n",
    "VAL_IMG_ROOT = \"./test\"\n",
    "SUBMISSION_PATH = \"./submission.csv\"\n",
    "\n",
    "# YOLO dataset structure\n",
    "YOLO_DATASET_ROOT = \"./yolo_dataset\"\n",
    "YOLO_TRAIN_IMG = os.path.join(YOLO_DATASET_ROOT, \"images\", \"train\")\n",
    "YOLO_VAL_IMG = os.path.join(YOLO_DATASET_ROOT, \"images\", \"val\")\n",
    "YOLO_TRAIN_LABEL = os.path.join(YOLO_DATASET_ROOT, \"labels\", \"train\")\n",
    "YOLO_VAL_LABEL = os.path.join(YOLO_DATASET_ROOT, \"labels\", \"val\")\n",
    "\n",
    "# === LABELS ===\n",
    "LABEL_MAP = {\n",
    "    'crazing': 0,\n",
    "    'inclusion': 1,\n",
    "    'patches': 2,\n",
    "    'pitted_surface': 3,\n",
    "    'rolled-in_scale': 4,\n",
    "    'scratches': 5\n",
    "}\n",
    "REV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "class DatasetConverter:\n",
    "    \"\"\"Convert XML annotations to YOLO format\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, ann_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        \n",
    "    def xml_to_yolo_bbox(self, bbox, img_width, img_height):\n",
    "        \"\"\"Convert XML bbox to YOLO format (normalized center coordinates and dimensions)\"\"\"\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        \n",
    "        # Calculate center coordinates and dimensions\n",
    "        x_center = (xmin + xmax) / 2.0\n",
    "        y_center = (ymin + ymax) / 2.0\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        \n",
    "        # Normalize coordinates\n",
    "        x_center /= img_width\n",
    "        y_center /= img_height\n",
    "        width /= img_width\n",
    "        height /= img_height\n",
    "        \n",
    "        return [x_center, y_center, width, height]\n",
    "    \n",
    "    def convert_annotation(self, xml_path, img_path):\n",
    "        \"\"\"Convert single XML annotation to YOLO format\"\"\"\n",
    "        # Get image dimensions\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        \n",
    "        # Parse XML\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        yolo_annotations = []\n",
    "        for obj in root.findall('object'):\n",
    "            label = obj.find('name').text\n",
    "            if label not in LABEL_MAP:\n",
    "                continue\n",
    "                \n",
    "            class_id = LABEL_MAP[label]\n",
    "            \n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text)\n",
    "            ymin = float(bbox.find('ymin').text)\n",
    "            xmax = float(bbox.find('xmax').text)\n",
    "            ymax = float(bbox.find('ymax').text)\n",
    "            \n",
    "            # Convert to YOLO format\n",
    "            yolo_bbox = self.xml_to_yolo_bbox([xmin, ymin, xmax, ymax], img_width, img_height)\n",
    "            yolo_annotations.append([class_id] + yolo_bbox)\n",
    "            \n",
    "        return yolo_annotations\n",
    "    \n",
    "    def create_yolo_dataset(self, train_split=0.8):\n",
    "        \"\"\"Create YOLO dataset structure\"\"\"\n",
    "        # Create directories\n",
    "        os.makedirs(YOLO_TRAIN_IMG, exist_ok=True)\n",
    "        os.makedirs(YOLO_VAL_IMG, exist_ok=True)\n",
    "        os.makedirs(YOLO_TRAIN_LABEL, exist_ok=True)\n",
    "        os.makedirs(YOLO_VAL_LABEL, exist_ok=True)\n",
    "        \n",
    "        # Get all image files\n",
    "        img_files = [f for f in os.listdir(self.img_dir) if f.endswith('.jpg')]\n",
    "        img_files.sort()\n",
    "        \n",
    "        # Split dataset\n",
    "        num_train = int(len(img_files) * train_split)\n",
    "        train_files = img_files[:num_train]\n",
    "        val_files = img_files[num_train:]\n",
    "        \n",
    "        print(f\"Converting dataset: {len(train_files)} train, {len(val_files)} val\")\n",
    "        \n",
    "        # Process training set\n",
    "        for img_file in tqdm(train_files, desc=\"Converting train set\"):\n",
    "            img_path = os.path.join(self.img_dir, img_file)\n",
    "            xml_path = os.path.join(self.ann_dir, img_file.replace('.jpg', '.xml'))\n",
    "            \n",
    "            if not os.path.exists(xml_path):\n",
    "                continue\n",
    "                \n",
    "            # Copy image\n",
    "            shutil.copy2(img_path, os.path.join(YOLO_TRAIN_IMG, img_file))\n",
    "            \n",
    "            # Convert and save annotation\n",
    "            yolo_annotations = self.convert_annotation(xml_path, img_path)\n",
    "            \n",
    "            txt_file = img_file.replace('.jpg', '.txt')\n",
    "            txt_path = os.path.join(YOLO_TRAIN_LABEL, txt_file)\n",
    "            \n",
    "            with open(txt_path, 'w') as f:\n",
    "                for annotation in yolo_annotations:\n",
    "                    f.write(' '.join(map(str, annotation)) + '\\n')\n",
    "        \n",
    "        # Process validation set\n",
    "        for img_file in tqdm(val_files, desc=\"Converting val set\"):\n",
    "            img_path = os.path.join(self.img_dir, img_file)\n",
    "            xml_path = os.path.join(self.ann_dir, img_file.replace('.jpg', '.xml'))\n",
    "            \n",
    "            if not os.path.exists(xml_path):\n",
    "                continue\n",
    "                \n",
    "            # Copy image\n",
    "            shutil.copy2(img_path, os.path.join(YOLO_VAL_IMG, img_file))\n",
    "            \n",
    "            # Convert and save annotation\n",
    "            yolo_annotations = self.convert_annotation(xml_path, img_path)\n",
    "            \n",
    "            txt_file = img_file.replace('.jpg', '.txt')\n",
    "            txt_path = os.path.join(YOLO_VAL_LABEL, txt_file)\n",
    "            \n",
    "            with open(txt_path, 'w') as f:\n",
    "                for annotation in yolo_annotations:\n",
    "                    f.write(' '.join(map(str, annotation)) + '\\n')\n",
    "        \n",
    "        # Create dataset configuration file\n",
    "        self.create_dataset_yaml()\n",
    "        \n",
    "        print(f\"YOLO dataset created successfully!\")\n",
    "        \n",
    "    def create_dataset_yaml(self):\n",
    "        \"\"\"Create YOLO dataset configuration file\"\"\"\n",
    "        dataset_config = {\n",
    "            'path': os.path.abspath(YOLO_DATASET_ROOT),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'names': {i: name for name, i in LABEL_MAP.items()},\n",
    "            'nc': NUM_CLASSES\n",
    "        }\n",
    "        \n",
    "        yaml_path = os.path.join(YOLO_DATASET_ROOT, 'dataset.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "        \n",
    "        return yaml_path\n",
    "\n",
    "class ImprovedYOLOTrainer:\n",
    "    \"\"\"Enhanced YOLO trainer with advanced features\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='yolov8n.pt', img_size=640):\n",
    "        self.model_name = model_name\n",
    "        self.img_size = img_size\n",
    "        self.model = None\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load YOLO model with custom modifications\"\"\"\n",
    "        self.model = YOLO(self.model_name)\n",
    "        \n",
    "        # Modify model architecture for better performance\n",
    "        # Add dropout layers and modify head architecture\n",
    "        if hasattr(self.model.model, 'model'):\n",
    "            # Add custom modifications here\n",
    "            print(\"Model loaded and ready for training\")\n",
    "        \n",
    "    def create_augmentation_pipeline(self):\n",
    "        \"\"\"Create advanced data augmentation pipeline\"\"\"\n",
    "        transform = A.Compose([\n",
    "            A.RandomRotate90(p=0.3),\n",
    "            A.Flip(p=0.3),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, \n",
    "                contrast_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10,\n",
    "                sat_shift_limit=15,\n",
    "                val_shift_limit=10,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=10, p=0.2),\n",
    "            A.MotionBlur(blur_limit=3, p=0.2),\n",
    "            A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1,\n",
    "                scale_limit=0.1,\n",
    "                rotate_limit=15,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=0,\n",
    "                p=0.3\n",
    "            ),\n",
    "        ], bbox_params=BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "        \n",
    "        return transform\n",
    "    \n",
    "    def train_model(self, data_yaml, epochs=100, batch_size=16, patience=20):\n",
    "        \"\"\"Train YOLO model with advanced configurations\"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        training_args = {\n",
    "            'data': data_yaml,\n",
    "            'epochs': epochs,\n",
    "            'batch': batch_size,\n",
    "            'imgsz': self.img_size,\n",
    "            'device': DEVICE,\n",
    "            'patience': patience,\n",
    "            'save_period': 10,\n",
    "            'workers': 4,\n",
    "            'project': 'runs/detect',\n",
    "            'name': 'neudet_improved',\n",
    "            'exist_ok': True,\n",
    "            \n",
    "            # Optimization settings\n",
    "            'optimizer': 'AdamW',\n",
    "            'lr0': 0.001,\n",
    "            'lrf': 0.01,\n",
    "            'momentum': 0.937,\n",
    "            'weight_decay': 0.0005,\n",
    "            'warmup_epochs': 3,\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,\n",
    "            \n",
    "            # Augmentation settings\n",
    "            'hsv_h': 0.015,\n",
    "            'hsv_s': 0.7,\n",
    "            'hsv_v': 0.4,\n",
    "            'degrees': 15.0,\n",
    "            'translate': 0.1,\n",
    "            'scale': 0.5,\n",
    "            'shear': 0.0,\n",
    "            'perspective': 0.0,\n",
    "            'flipud': 0.0,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 1.0,\n",
    "            'mixup': 0.1,\n",
    "            'copy_paste': 0.1,\n",
    "            \n",
    "            # Loss settings\n",
    "            'box': 7.5,\n",
    "            'cls': 0.5,\n",
    "            'dfl': 1.5,\n",
    "            \n",
    "            # Other settings\n",
    "            'val': True,\n",
    "            'plots': True,\n",
    "            'save_json': True,\n",
    "            'verbose': True\n",
    "        }\n",
    "        \n",
    "        print(\"Starting training with improved YOLO model...\")\n",
    "        results = self.model.train(**training_args)\n",
    "        \n",
    "        # Save the best model\n",
    "        best_model_path = f\"runs/detect/neudet_improved/weights/best.pt\"\n",
    "        print(f\"Training completed! Best model saved at: {best_model_path}\")\n",
    "        \n",
    "        return results, best_model_path\n",
    "\n",
    "class InferenceEngine:\n",
    "    \"\"\"Enhanced inference engine for predictions\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, conf_threshold=0.25, iou_threshold=0.45):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        \n",
    "    def predict_and_export(self, test_dir, save_csv_path, save_img_dir=\"output\", \n",
    "                          visualize=True, tta=False):\n",
    "        \"\"\"Enhanced prediction with TTA and better post-processing\"\"\"\n",
    "        os.makedirs(save_img_dir, exist_ok=True)\n",
    "        rows = []\n",
    "        \n",
    "        test_images = sorted([f for f in os.listdir(test_dir) \n",
    "                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        \n",
    "        print(f\"Processing {len(test_images)} test images...\")\n",
    "        \n",
    "        for img_file in tqdm(test_images, desc=\"Predicting\"):\n",
    "            img_path = os.path.join(test_dir, img_file)\n",
    "            \n",
    "            # Run inference with optional TTA\n",
    "            if tta:\n",
    "                results = self.predict_with_tta(img_path)\n",
    "            else:\n",
    "                results = self.model(img_path, \n",
    "                                   conf=self.conf_threshold,\n",
    "                                   iou=self.iou_threshold,\n",
    "                                   imgsz=IMG_SIZE,\n",
    "                                   device=DEVICE,\n",
    "                                   augment=True)\n",
    "            \n",
    "            # Process results\n",
    "            if len(results) > 0 and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes\n",
    "                \n",
    "                if len(boxes) > 0:\n",
    "                    # Extract predictions\n",
    "                    conf_scores = boxes.conf.cpu().numpy()\n",
    "                    class_ids = boxes.cls.cpu().numpy().astype(int)\n",
    "                    bbox_coords = boxes.xyxy.cpu().numpy()\n",
    "                    \n",
    "                    # Apply additional filtering\n",
    "                    valid_indices = self.apply_post_processing(\n",
    "                        bbox_coords, conf_scores, class_ids\n",
    "                    )\n",
    "                    \n",
    "                    if len(valid_indices) > 0:\n",
    "                        conf_scores = conf_scores[valid_indices]\n",
    "                        class_ids = class_ids[valid_indices]\n",
    "                        bbox_coords = bbox_coords[valid_indices]\n",
    "                        \n",
    "                        # Create submission row\n",
    "                        row = self.create_submission_row(\n",
    "                            img_file, bbox_coords, conf_scores, class_ids\n",
    "                        )\n",
    "                        rows.append(row)\n",
    "                        \n",
    "                        # Visualize if requested\n",
    "                        if visualize:\n",
    "                            self.visualize_predictions(\n",
    "                                img_path, bbox_coords, conf_scores, class_ids, \n",
    "                                save_img_dir, img_file\n",
    "                            )\n",
    "                    else:\n",
    "                        # No valid detections\n",
    "                        rows.append(self.create_empty_row(img_file))\n",
    "                else:\n",
    "                    # No detections\n",
    "                    rows.append(self.create_empty_row(img_file))\n",
    "            else:\n",
    "                # No detections\n",
    "                rows.append(self.create_empty_row(img_file))\n",
    "        \n",
    "        # Save results to CSV\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.fillna(\"none\", inplace=True)\n",
    "        df.to_csv(save_csv_path, index=False)\n",
    "        \n",
    "        print(f\"[INFO] Saved CSV to {save_csv_path}\")\n",
    "        if visualize:\n",
    "            print(f\"[INFO] Saved annotated images to {save_img_dir}/\")\n",
    "        \n",
    "        # Print detection statistics\n",
    "        self.print_detection_stats(df)\n",
    "        \n",
    "    def predict_with_tta(self, img_path):\n",
    "        \"\"\"Test Time Augmentation for better predictions\"\"\"\n",
    "        transforms = [\n",
    "            lambda x: x,  # Original\n",
    "            lambda x: cv2.flip(x, 1),  # Horizontal flip\n",
    "            lambda x: cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE),  # 90° rotation\n",
    "            lambda x: cv2.rotate(x, cv2.ROTATE_90_COUNTERCLOCKWISE),  # -90° rotation\n",
    "        ]\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        all_results = []\n",
    "        \n",
    "        for transform in transforms:\n",
    "            transformed_img = transform(img.copy())\n",
    "            temp_path = \"temp_tta.jpg\"\n",
    "            cv2.imwrite(temp_path, transformed_img)\n",
    "            \n",
    "            results = self.model(temp_path,\n",
    "                               conf=self.conf_threshold,\n",
    "                               iou=self.iou_threshold,\n",
    "                               imgsz=IMG_SIZE,\n",
    "                               device=DEVICE)\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        # Clean up temp file\n",
    "        if os.path.exists(\"temp_tta.jpg\"):\n",
    "            os.remove(\"temp_tta.jpg\")\n",
    "        \n",
    "        # Ensemble results (simplified - in practice, you'd want proper coordinate transformation)\n",
    "        return all_results[:1]  # Return first result for now\n",
    "        \n",
    "    def apply_post_processing(self, boxes, scores, classes):\n",
    "        \"\"\"Apply additional post-processing filters\"\"\"\n",
    "        valid_indices = []\n",
    "        \n",
    "        for i, (box, score, cls) in enumerate(zip(boxes, scores, classes)):\n",
    "            x1, y1, x2, y2 = box\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            area = width * height\n",
    "            \n",
    "            # Filter by minimum area and aspect ratio\n",
    "            if area > 100 and 0.1 < width/height < 10:\n",
    "                valid_indices.append(i)\n",
    "        \n",
    "        return valid_indices\n",
    "    \n",
    "    def create_submission_row(self, img_file, boxes, scores, classes):\n",
    "        \"\"\"Create submission row with proper formatting\"\"\"\n",
    "        # Take the highest confidence detection as primary label\n",
    "        best_idx = np.argmax(scores)\n",
    "        primary_label = REV_LABEL_MAP[classes[best_idx]]\n",
    "        \n",
    "        # Format all detections\n",
    "        cf_list = [f\"{score:.3f}\" for score in scores]\n",
    "        xmin_list = [str(int(box[0])) for box in boxes]\n",
    "        ymin_list = [str(int(box[1])) for box in boxes]\n",
    "        xmax_list = [str(int(box[2])) for box in boxes]\n",
    "        ymax_list = [str(int(box[3])) for box in boxes]\n",
    "        \n",
    "        return {\n",
    "            \"ID\": img_file,\n",
    "            \"label\": primary_label,\n",
    "            \"cf\": \" \".join(cf_list),\n",
    "            \"xmin\": \" \".join(xmin_list),\n",
    "            \"ymin\": \" \".join(ymin_list),\n",
    "            \"xmax\": \" \".join(xmax_list),\n",
    "            \"ymax\": \" \".join(ymax_list),\n",
    "        }\n",
    "    \n",
    "    def create_empty_row(self, img_file):\n",
    "        \"\"\"Create empty row for images with no detections\"\"\"\n",
    "        return {\n",
    "            \"ID\": img_file,\n",
    "            \"label\": \"none\",\n",
    "            \"cf\": \"0\",\n",
    "            \"xmin\": \"0\",\n",
    "            \"ymin\": \"0\",\n",
    "            \"xmax\": \"0\",\n",
    "            \"ymax\": \"0\",\n",
    "        }\n",
    "    \n",
    "    def visualize_predictions(self, img_path, boxes, scores, classes, \n",
    "                            save_dir, img_file):\n",
    "        \"\"\"Visualize predictions with improved styling\"\"\"\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, NUM_CLASSES))\n",
    "        \n",
    "        for box, score, cls in zip(boxes, scores, classes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            color = colors[cls]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            rect = patches.Rectangle((x1, y1), width, height,\n",
    "                                   linewidth=2, edgecolor=color, \n",
    "                                   facecolor='none', alpha=0.8)\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add label with background\n",
    "            label_text = f\"{REV_LABEL_MAP[cls]}: {score:.3f}\"\n",
    "            ax.text(x1, y1 - 5, label_text,\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7),\n",
    "                   fontsize=10, color='black', weight='bold')\n",
    "        \n",
    "        ax.set_title(f\"Detections: {img_file}\", fontsize=14, weight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Save with high quality\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, img_file), \n",
    "                   dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    def print_detection_stats(self, df):\n",
    "        \"\"\"Print detection statistics\"\"\"\n",
    "        total_images = len(df)\n",
    "        images_with_detections = len(df[df['label'] != 'none'])\n",
    "        \n",
    "        print(f\"\\n=== Detection Statistics ===\")\n",
    "        print(f\"Total images processed: {total_images}\")\n",
    "        print(f\"Images with detections: {images_with_detections}\")\n",
    "        print(f\"Images without detections: {total_images - images_with_detections}\")\n",
    "        print(f\"Detection rate: {images_with_detections/total_images*100:.1f}%\")\n",
    "        \n",
    "        # Class distribution\n",
    "        if images_with_detections > 0:\n",
    "            class_counts = df[df['label'] != 'none']['label'].value_counts()\n",
    "            print(f\"\\nClass distribution:\")\n",
    "            for class_name, count in class_counts.items():\n",
    "                print(f\"  {class_name}: {count}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"=== NEU-DET Object Detection with Improved YOLO ===\")\n",
    "    \n",
    "    # Step 1: Convert dataset to YOLO format\n",
    "    print(\"\\n1. Converting dataset to YOLO format...\")\n",
    "    converter = DatasetConverter(TRAIN_IMG_ROOT, TRAIN_ANN_ROOT)\n",
    "    converter.create_yolo_dataset(train_split=0.85)\n",
    "    \n",
    "    # Step 2: Initialize and train model\n",
    "    print(\"\\n2. Initializing YOLO trainer...\")\n",
    "    trainer = ImprovedYOLOTrainer(model_name='yolov8m.pt', img_size=IMG_SIZE)\n",
    "    \n",
    "    dataset_yaml = os.path.join(YOLO_DATASET_ROOT, 'dataset.yaml')\n",
    "    \n",
    "    print(\"\\n3. Starting training...\")\n",
    "    results, best_model_path = trainer.train_model(\n",
    "        data_yaml=dataset_yaml,\n",
    "        epochs=150,\n",
    "        batch_size=16,\n",
    "        patience=25\n",
    "    )\n",
    "    \n",
    "    # Step 3: Run inference\n",
    "    print(\"\\n4. Running inference on test set...\")\n",
    "    inference_engine = InferenceEngine(\n",
    "        model_path=best_model_path,\n",
    "        conf_threshold=CONF_THRESHOLD,\n",
    "        iou_threshold=IOU_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    inference_engine.predict_and_export(\n",
    "        test_dir=VAL_IMG_ROOT,\n",
    "        save_csv_path=SUBMISSION_PATH,\n",
    "        save_img_dir=\"output_visualizations\",\n",
    "        visualize=True,\n",
    "        tta=False  # Set to True for Test Time Augmentation\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Training and Inference Complete! ===\")\n",
    "    print(f\"Submission file saved to: {SUBMISSION_PATH}\")\n",
    "    print(\"Check the runs/detect/neudet_improved/ folder for training logs and metrics.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Install required packages if not already installed\n",
    "    try:\n",
    "        import ultralytics\n",
    "        import albumentations\n",
    "    except ImportError:\n",
    "        print(\"Installing required packages...\")\n",
    "        os.system(\"pip install ultralytics albumentations\")\n",
    "        print(\"Packages installed. Please restart and run again.\")\n",
    "        exit()\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
